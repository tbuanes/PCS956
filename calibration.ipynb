{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Calibration\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A machine learning model for classification typically output a value (or one value per class for multiclass classification) which is used to determine the predicted class. In the case of binary classification, one typically apply a threshold such that if the number is above threshold the instance is predicted to belong to the positive class. For multiclassification, one typically choose the class associated with the largest output. Instead of only using a threshold or the class with the largest output number one can try to extract more informantion from the output value itself. Assume that the value is in the range [0,1].^[It is common to use a sigmoid or softmax function in the last layer of a NN such that the output is in this range.] The closer to 1, the more confident we can be in the classification. \n",
    "\n",
    ":::{.callout-warning}\n",
    "Since the output is commonly transformed to be in the range [0,1] it looks like, and is often interpreted as, probability. I.e., if the output value is 0.95 one would interpret that the instance has 95% probability of belonging to that class. This is generally not true. Instead of quoting the value as a probability, we should call it *ML output* or *confidence*.\n",
    ":::\n",
    "\n",
    "Allthough the output cannot be interpreted as probability there is often (but not always) a one-to-one relation between the output value and the true probability. To obtain the probability from the ML output, one can apply a calibration step after training the ML model. \n",
    "\n",
    "It has been observed^[[On Calibration of Modern Neural Networks](https://proceedings.mlr.press/v70/guo17a.html) \\C Guo, G Pleiss, Y Sun, and K Weinberger \\Proceedings of the 34th International Conference on Machine Learning, PMLR 70:1321-1330, 2017] that the developments in ML over the last years that has produced a much better accuracy at the same time tend to lead to more mis-calibrated results out of the box. Thus, the need for calibration seems to be larger the more complex the ML model is."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
